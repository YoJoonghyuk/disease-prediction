{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "import re\n",
        "import os"
      ],
      "metadata": {
        "id": "glBIgkIGaA-f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"dataset.csv\")"
      ],
      "metadata": {
        "id": "kromn2PWaA0Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Предобработка данных\n",
        "df.columns = df.columns.str.replace(' ', '')\n",
        "df = df.replace('none', np.nan)\n",
        "\n",
        "def create_text(row):\n",
        "    symptoms = []\n",
        "    for col in df.columns:\n",
        "        if col.startswith('Symptom') and not pd.isna(row[col]):\n",
        "            symptoms.append(row[col])\n",
        "    return ' '.join(symptoms)\n",
        "\n",
        "df['text_description'] = df.apply(create_text, axis=1)\n",
        "\n",
        "df = df.dropna(subset=['text_description'])\n",
        "\n",
        "class_counts = df['Disease'].value_counts()\n",
        "rare_classes = class_counts[class_counts < 5].index\n",
        "df = df[~df['Disease'].isin(rare_classes)]\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['Disease'] = le.fit_transform(df['Disease'])"
      ],
      "metadata": {
        "id": "HN6VDqn6aArg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Предобработка текста:\n",
        "def preprocess_text(text):\n",
        "    text = text.replace('.', ' <PERIOD> ')\n",
        "    text = text.replace(',', ' <COMMA> ')\n",
        "    text = text.replace('?', ' <QUESTION> ')\n",
        "    text = text.replace('_', ' ')\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "df['text_description'] = df['text_description'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "Jyf6Co9waNN6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Подготовка данных для GRU\n",
        "MAX_NB_WORDS = 30000\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(df['text_description'])\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df['text_description'])\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "Y = df['Disease']"
      ],
      "metadata": {
        "id": "_f-K-vz2aOui"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
        "y_train = to_categorical(y_train, num_classes=len(le.classes_))\n",
        "y_test = to_categorical(y_test, num_classes=len(le.classes_))"
      ],
      "metadata": {
        "id": "q7YxbpBfaWU9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Создание GRU модели\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(len(le.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "BYmV9Y5GaX70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "7a040e0a-03da-410b-9601-a1d348a40a2e",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Обучение модели\n",
        "epochs = 3\n",
        "batch_size = 32\n",
        "\n",
        "# Замер времени обучения\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=1)\n",
        "training_time = time.time() - start_time\n",
        "print(f\"Training Time: {training_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "-xZeyHiLadma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8954ed2-cfc6-4cca-ed98-0fa7e10acb5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.5603 - loss: 3.0373 - precision_1: 0.4004 - recall_1: 0.0406 - val_accuracy: 0.9924 - val_loss: 0.2405 - val_precision_1: 1.0000 - val_recall_1: 0.9442\n",
            "Epoch 2/3\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9940 - loss: 0.1348 - precision_1: 0.9975 - recall_1: 0.9804 - val_accuracy: 0.9975 - val_loss: 0.0413 - val_precision_1: 0.9975 - val_recall_1: 0.9949\n",
            "Epoch 3/3\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9972 - loss: 0.0332 - precision_1: 0.9972 - recall_1: 0.9961 - val_accuracy: 0.9975 - val_loss: 0.0189 - val_precision_1: 0.9975 - val_recall_1: 0.9975\n",
            "Training Time: 9.9229 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Оценка модели\n",
        "start_time = time.time()\n",
        "loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
        "prediction_time = time.time() - start_time\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f\"Prediction Time: {prediction_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "vDo_qVweadYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f601f087-1e55-42f1-b300-52c13932dd3b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9980\n",
            "Precision: 0.9980\n",
            "Recall: 0.9980\n",
            "Prediction Time: 0.3793 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Classification Report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "print(classification_report(y_test_labels, y_pred, zero_division=0))"
      ],
      "metadata": {
        "id": "2GXLYGdJaiCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bd5248-7139-4f77-accb-1d743c77ef4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        24\n",
            "           1       1.00      1.00      1.00        24\n",
            "           2       1.00      1.00      1.00        24\n",
            "           3       1.00      1.00      1.00        24\n",
            "           4       1.00      1.00      1.00        24\n",
            "           5       1.00      1.00      1.00        24\n",
            "           6       1.00      1.00      1.00        24\n",
            "           7       1.00      1.00      1.00        24\n",
            "           8       1.00      1.00      1.00        24\n",
            "           9       0.92      1.00      0.96        24\n",
            "          10       1.00      1.00      1.00        24\n",
            "          11       1.00      1.00      1.00        24\n",
            "          12       1.00      1.00      1.00        24\n",
            "          13       1.00      1.00      1.00        24\n",
            "          14       1.00      1.00      1.00        24\n",
            "          15       1.00      1.00      1.00        24\n",
            "          16       1.00      1.00      1.00        24\n",
            "          17       1.00      1.00      1.00        24\n",
            "          18       1.00      1.00      1.00        24\n",
            "          19       1.00      1.00      1.00        24\n",
            "          20       1.00      0.92      0.96        24\n",
            "          21       1.00      1.00      1.00        24\n",
            "          22       1.00      1.00      1.00        24\n",
            "          23       1.00      1.00      1.00        24\n",
            "          24       1.00      1.00      1.00        24\n",
            "          25       1.00      1.00      1.00        24\n",
            "          26       1.00      1.00      1.00        24\n",
            "          27       1.00      1.00      1.00        24\n",
            "          28       1.00      1.00      1.00        24\n",
            "          29       1.00      1.00      1.00        24\n",
            "          30       1.00      1.00      1.00        24\n",
            "          31       1.00      1.00      1.00        24\n",
            "          32       1.00      1.00      1.00        24\n",
            "          33       1.00      1.00      1.00        24\n",
            "          34       1.00      1.00      1.00        24\n",
            "          35       1.00      1.00      1.00        24\n",
            "          36       1.00      1.00      1.00        24\n",
            "          37       1.00      1.00      1.00        24\n",
            "          38       1.00      1.00      1.00        24\n",
            "          39       1.00      1.00      1.00        24\n",
            "          40       1.00      1.00      1.00        24\n",
            "\n",
            "    accuracy                           1.00       984\n",
            "   macro avg       1.00      1.00      1.00       984\n",
            "weighted avg       1.00      1.00      1.00       984\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение модели\n",
        "model.save(\"gru_model.h5\")\n",
        "\n",
        "# Определение размера модели\n",
        "model_size = os.path.getsize(\"gru_model.h5\") / (1024 * 1024)\n",
        "print(f\"Model Size: {model_size:.4f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QcY7Q063xbV",
        "outputId": "aaab283c-1860-4991-b21c-d85d267ce82d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 35.4366 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Сохранение токенизатора\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Сохранение LabelEncoder\n",
        "with open('label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(le, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "38IB3Mz7mcRz"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}